This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2025-05-04T09:57:11.860Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
app/
  page.jsx
backend/
  app.py
  requirements.txt
  tempCodeRunnerFile.py
public/
  brain.svg
  placeholder-logo.svg
  placeholder.svg
src/
  assets/
    react.svg
  components/
    BackgroundAnimation.jsx
    CameraSection.jsx
    Footer.jsx
    Header.jsx
    InfoSection.jsx
    ResultsPanel.jsx
  services/
    api.js
  App.css
  App.jsx
  main.jsx
.gitattributes
.gitignore
eslint.config.js
index.html
LICENSE
package.json
README.md
vite.config.js

================================================================
Repository Files
================================================================

================
File: app/page.jsx
================
import App from "../src/App"

export default function Page() {
  return <App />
}

================
File: backend/app.py
================
from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
from transformers import AutoImageProcessor, AutoModelForImageClassification
from PIL import Image
import base64
import io
import numpy as np

app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

# Load the model and processor once when the app starts
print("Loading model...")
processor = AutoImageProcessor.from_pretrained("trpakov/vit-face-expression")
model = AutoModelForImageClassification.from_pretrained("trpakov/vit-face-expression")
print("Model loaded!")

@app.route('/detect', methods=['POST'])
def detect_emotion():
    try:
        # Get the base64 image from the request
        data = request.json
        if 'image' not in data:
            return jsonify({"error": "No image provided"}), 400
        
        # Decode the base64 image
        image_data = data['image'].split(',')[1] if ',' in data['image'] else data['image']
        image = Image.open(io.BytesIO(base64.b64decode(image_data)))
        
        # Process the image and get predictions
        inputs = processor(images=image, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
        
        # Get predicted class and confidences
        predicted_class_idx = logits.argmax(-1).item()
        scores = torch.nn.functional.softmax(logits, dim=-1)[0].tolist()
        
        # Get all class names with their confidence scores
        results = []
        for idx, score in enumerate(scores):
            emotion = model.config.id2label[idx]
            results.append({
                "emotion": emotion.capitalize(),
                "confidence": score
            })
        
        # Sort by confidence in descending order
        results.sort(key=lambda x: x["confidence"], reverse=True)
        
        # Format the response
        return jsonify({
            "primaryEmotion": results[0]["emotion"],
            "confidence": results[0]["confidence"] * 100,
            "allResults": results
        })
    
    except Exception as e:
        print(f"Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=3000)

================
File: backend/requirements.txt
================
flask
flask-cors
torch
transformers
Pillow
numpy

================
File: backend/tempCodeRunnerFile.py
================
torch

================
File: public/brain.svg
================
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#666666" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
  <path d="M9.5 2A2.5 2.5 0 0 1 12 4.5v15a2.5 2.5 0 0 1-4.96.44 2.5 2.5 0 0 1-2.96-3.08 3 3 0 0 1-.34-5.58 2.5 2.5 0 0 1 1.32-4.24 2.5 2.5 0 0 1 1.98-3A2.5 2.5 0 0 1 9.5 2Z"></path>
  <path d="M14.5 2A2.5 2.5 0 0 0 12 4.5v15a2.5 2.5 0 0 0 4.96.44 2.5 2.5 0 0 0 2.96-3.08 3 3 0 0 0 .34-5.58 2.5 2.5 0 0 0-1.32-4.24 2.5 2.5 0 0 0-1.98-3A2.5 2.5 0 0 0 14.5 2Z"></path>
</svg>

================
File: public/placeholder-logo.svg
================
<svg xmlns="http://www.w3.org/2000/svg" width="215" height="48" fill="none"><path fill="#000" d="M57.588 9.6h6L73.828 38h-5.2l-2.36-6.88h-11.36L52.548 38h-5.2l10.24-28.4Zm7.16 17.16-4.16-12.16-4.16 12.16h8.32Zm23.694-2.24c-.186-1.307-.706-2.32-1.56-3.04-.853-.72-1.866-1.08-3.04-1.08-1.68 0-2.986.613-3.92 1.84-.906 1.227-1.36 2.947-1.36 5.16s.454 3.933 1.36 5.16c.934 1.227 2.24 1.84 3.92 1.84 1.254 0 2.307-.373 3.16-1.12.854-.773 1.387-1.867 1.6-3.28l5.12.24c-.186 1.68-.733 3.147-1.64 4.4-.906 1.227-2.08 2.173-3.52 2.84-1.413.667-2.986 1-4.72 1-2.08 0-3.906-.453-5.48-1.36-1.546-.907-2.76-2.2-3.64-3.88-.853-1.68-1.28-3.627-1.28-5.84 0-2.24.427-4.187 1.28-5.84.88-1.68 2.094-2.973 3.64-3.88 1.574-.907 3.4-1.36 5.48-1.36 1.68 0 3.227.32 4.64.96 1.414.64 2.56 1.56 3.44 2.76.907 1.2 1.454 2.6 1.64 4.2l-5.12.28Zm11.486-7.72.12 3.4c.534-1.227 1.307-2.173 2.32-2.84 1.04-.693 2.267-1.04 3.68-1.04 1.494 0 2.76.387 3.8 1.16 1.067.747 1.827 1.813 2.28 3.2.507-1.44 1.294-2.52 2.36-3.24 1.094-.747 2.414-1.12 3.96-1.12 1.414 0 2.64.307 3.68.92s1.84 1.52 2.4 2.72c.56 1.2.84 2.667.84 4.4V38h-4.96V25.92c0-1.813-.293-3.187-.88-4.12-.56-.96-1.413-1.44-2.56-1.44-.906 0-1.68.213-2.32.64-.64.427-1.133 1.053-1.48 1.88-.32.827-.48 1.84-.48 3.04V38h-4.56V25.92c0-1.2-.133-2.213-.4-3.04-.24-.827-.626-1.453-1.16-1.88-.506-.427-1.133-.64-1.88-.64-.906 0-1.68.227-2.32.68-.64.427-1.133 1.053-1.48 1.88-.32.827-.48 1.827-.48 3V38h-4.96V16.8h4.48Zm26.723 10.6c0-2.24.427-4.187 1.28-5.84.854-1.68 2.067-2.973 3.64-3.88 1.574-.907 3.4-1.36 5.48-1.36 1.84 0 3.494.413 4.96 1.24 1.467.827 2.64 2.08 3.52 3.76.88 1.653 1.347 3.693 1.4 6.12v1.32h-15.08c.107 1.813.614 3.227 1.52 4.24.907.987 2.134 1.48 3.68 1.48.987 0 1.88-.253 2.68-.76a4.803 4.803 0 0 0 1.84-2.2l5.08.36c-.64 2.027-1.84 3.64-3.6 4.84-1.733 1.173-3.733 1.76-6 1.76-2.08 0-3.906-.453-5.48-1.36-1.573-.907-2.786-2.2-3.64-3.88-.853-1.68-1.28-3.627-1.28-5.84Zm15.16-2.04c-.213-1.733-.76-3.013-1.64-3.84-.853-.827-1.893-1.24-3.12-1.24-1.44 0-2.6.453-3.48 1.36-.88.88-1.44 2.12-1.68 3.72h9.92ZM163.139 9.6V38h-5.04V9.6h5.04Zm8.322 7.2.24 5.88-.64-.36c.32-2.053 1.094-3.56 2.32-4.52 1.254-.987 2.787-1.48 4.6-1.48 2.32 0 4.107.733 5.36 2.2 1.254 1.44 1.88 3.387 1.88 5.84V38h-4.96V25.92c0-1.253-.12-2.28-.36-3.08-.24-.8-.64-1.413-1.2-1.84-.533-.427-1.253-.64-2.16-.64-1.44 0-2.573.48-3.4 1.44-.8.933-1.2 2.307-1.2 4.12V38h-4.96V16.8h4.48Zm30.003 7.72c-.186-1.307-.706-2.32-1.56-3.04-.853-.72-1.866-1.08-3.04-1.08-1.68 0-2.986.613-3.92 1.84-.906 1.227-1.36 2.947-1.36 5.16s.454 3.933 1.36 5.16c.934 1.227 2.24 1.84 3.92 1.84 1.254 0 2.307-.373 3.16-1.12.854-.773 1.387-1.867 1.6-3.28l5.12.24c-.186 1.68-.733 3.147-1.64 4.4-.906 1.227-2.08 2.173-3.52 2.84-1.413.667-2.986 1-4.72 1-2.08 0-3.906-.453-5.48-1.36-1.546-.907-2.76-2.2-3.64-3.88-.853-1.68-1.28-3.627-1.28-5.84 0-2.24.427-4.187 1.28-5.84.88-1.68 2.094-2.973 3.64-3.88 1.574-.907 3.4-1.36 5.48-1.36 1.68 0 3.227.32 4.64.96 1.414.64 2.56 1.56 3.44 2.76.907 1.2 1.454 2.6 1.64 4.2l-5.12.28Zm11.443 8.16V38h-5.6v-5.32h5.6Z"/><path fill="#171717" fill-rule="evenodd" d="m7.839 40.783 16.03-28.054L20 6 0 40.783h7.839Zm8.214 0H40L27.99 19.894l-4.02 7.032 3.976 6.914H20.02l-3.967 6.943Z" clip-rule="evenodd"/></svg>

================
File: public/placeholder.svg
================
<svg xmlns="http://www.w3.org/2000/svg" width="1200" height="1200" fill="none"><rect width="1200" height="1200" fill="#EAEAEA" rx="3"/><g opacity=".5"><g opacity=".5"><path fill="#FAFAFA" d="M600.709 736.5c-75.454 0-136.621-61.167-136.621-136.62 0-75.454 61.167-136.621 136.621-136.621 75.453 0 136.62 61.167 136.62 136.621 0 75.453-61.167 136.62-136.62 136.62Z"/><path stroke="#C9C9C9" stroke-width="2.418" d="M600.709 736.5c-75.454 0-136.621-61.167-136.621-136.62 0-75.454 61.167-136.621 136.621-136.621 75.453 0 136.62 61.167 136.62 136.621 0 75.453-61.167 136.62-136.62 136.62Z"/></g><path stroke="url(#a)" stroke-width="2.418" d="M0-1.209h553.581" transform="scale(1 -1) rotate(45 1163.11 91.165)"/><path stroke="url(#b)" stroke-width="2.418" d="M404.846 598.671h391.726"/><path stroke="url(#c)" stroke-width="2.418" d="M599.5 795.742V404.017"/><path stroke="url(#d)" stroke-width="2.418" d="m795.717 796.597-391.441-391.44"/><path fill="#fff" d="M600.709 656.704c-31.384 0-56.825-25.441-56.825-56.824 0-31.384 25.441-56.825 56.825-56.825 31.383 0 56.824 25.441 56.824 56.825 0 31.383-25.441 56.824-56.824 56.824Z"/><g clip-path="url(#e)"><path fill="#666" fill-rule="evenodd" d="M616.426 586.58h-31.434v16.176l3.553-3.554.531-.531h9.068l.074-.074 8.463-8.463h2.565l7.18 7.181V586.58Zm-15.715 14.654 3.698 3.699 1.283 1.282-2.565 2.565-1.282-1.283-5.2-5.199h-6.066l-5.514 5.514-.073.073v2.876a2.418 2.418 0 0 0 2.418 2.418h26.598a2.418 2.418 0 0 0 2.418-2.418v-8.317l-8.463-8.463-7.181 7.181-.071.072Zm-19.347 5.442v4.085a6.045 6.045 0 0 0 6.046 6.045h26.598a6.044 6.044 0 0 0 6.045-6.045v-7.108l1.356-1.355-1.282-1.283-.074-.073v-17.989h-38.689v23.43l-.146.146.146.147Z" clip-rule="evenodd"/></g><path stroke="#C9C9C9" stroke-width="2.418" d="M600.709 656.704c-31.384 0-56.825-25.441-56.825-56.824 0-31.384 25.441-56.825 56.825-56.825 31.383 0 56.824 25.441 56.824 56.825 0 31.383-25.441 56.824-56.824 56.824Z"/></g><defs><linearGradient id="a" x1="554.061" x2="-.48" y1=".083" y2=".087" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><linearGradient id="b" x1="796.912" x2="404.507" y1="599.963" y2="599.965" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><linearGradient id="c" x1="600.792" x2="600.794" y1="403.677" y2="796.082" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><linearGradient id="d" x1="404.85" x2="796.972" y1="403.903" y2="796.02" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><clipPath id="e"><path fill="#fff" d="M581.364 580.535h38.689v38.689h-38.689z"/></clipPath></defs></svg>

================
File: src/assets/react.svg
================
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="35.93" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 228"><path fill="#00D8FF" d="M210.483 73.824a171.49 171.49 0 0 0-8.24-2.597c.465-1.9.893-3.777 1.273-5.621c6.238-30.281 2.16-54.676-11.769-62.708c-13.355-7.7-35.196.329-57.254 19.526a171.23 171.23 0 0 0-6.375 5.848a155.866 155.866 0 0 0-4.241-3.917C100.759 3.829 77.587-4.822 63.673 3.233C50.33 10.957 46.379 33.89 51.995 62.588a170.974 170.974 0 0 0 1.892 8.48c-3.28.932-6.445 1.924-9.474 2.98C17.309 83.498 0 98.307 0 113.668c0 15.865 18.582 31.778 46.812 41.427a145.52 145.52 0 0 0 6.921 2.165a167.467 167.467 0 0 0-2.01 9.138c-5.354 28.2-1.173 50.591 12.134 58.266c13.744 7.926 36.812-.22 59.273-19.855a145.567 145.567 0 0 0 5.342-4.923a168.064 168.064 0 0 0 6.92 6.314c21.758 18.722 43.246 26.282 56.54 18.586c13.731-7.949 18.194-32.003 12.4-61.268a145.016 145.016 0 0 0-1.535-6.842c1.62-.48 3.21-.974 4.76-1.488c29.348-9.723 48.443-25.443 48.443-41.52c0-15.417-17.868-30.326-45.517-39.844Zm-6.365 70.984c-1.4.463-2.836.91-4.3 1.345c-3.24-10.257-7.612-21.163-12.963-32.432c5.106-11 9.31-21.767 12.459-31.957c2.619.758 5.16 1.557 7.61 2.4c23.69 8.156 38.14 20.213 38.14 29.504c0 9.896-15.606 22.743-40.946 31.14Zm-10.514 20.834c2.562 12.94 2.927 24.64 1.23 33.787c-1.524 8.219-4.59 13.698-8.382 15.893c-8.067 4.67-25.32-1.4-43.927-17.412a156.726 156.726 0 0 1-6.437-5.87c7.214-7.889 14.423-17.06 21.459-27.246c12.376-1.098 24.068-2.894 34.671-5.345a134.17 134.17 0 0 1 1.386 6.193ZM87.276 214.515c-7.882 2.783-14.16 2.863-17.955.675c-8.075-4.657-11.432-22.636-6.853-46.752a156.923 156.923 0 0 1 1.869-8.499c10.486 2.32 22.093 3.988 34.498 4.994c7.084 9.967 14.501 19.128 21.976 27.15a134.668 134.668 0 0 1-4.877 4.492c-9.933 8.682-19.886 14.842-28.658 17.94ZM50.35 144.747c-12.483-4.267-22.792-9.812-29.858-15.863c-6.35-5.437-9.555-10.836-9.555-15.216c0-9.322 13.897-21.212 37.076-29.293c2.813-.98 5.757-1.905 8.812-2.773c3.204 10.42 7.406 21.315 12.477 32.332c-5.137 11.18-9.399 22.249-12.634 32.792a134.718 134.718 0 0 1-6.318-1.979Zm12.378-84.26c-4.811-24.587-1.616-43.134 6.425-47.789c8.564-4.958 27.502 2.111 47.463 19.835a144.318 144.318 0 0 1 3.841 3.545c-7.438 7.987-14.787 17.08-21.808 26.988c-12.04 1.116-23.565 2.908-34.161 5.309a160.342 160.342 0 0 1-1.76-7.887Zm110.427 27.268a347.8 347.8 0 0 0-7.785-12.803c8.168 1.033 15.994 2.404 23.343 4.08c-2.206 7.072-4.956 14.465-8.193 22.045a381.151 381.151 0 0 0-7.365-13.322Zm-45.032-43.861c5.044 5.465 10.096 11.566 15.065 18.186a322.04 322.04 0 0 0-30.257-.006c4.974-6.559 10.069-12.652 15.192-18.18ZM82.802 87.83a323.167 323.167 0 0 0-7.227 13.238c-3.184-7.553-5.909-14.98-8.134-22.152c7.304-1.634 15.093-2.97 23.209-3.984a321.524 321.524 0 0 0-7.848 12.897Zm8.081 65.352c-8.385-.936-16.291-2.203-23.593-3.793c2.26-7.3 5.045-14.885 8.298-22.6a321.187 321.187 0 0 0 7.257 13.246c2.594 4.48 5.28 8.868 8.038 13.147Zm37.542 31.03c-5.184-5.592-10.354-11.779-15.403-18.433c4.902.192 9.899.29 14.978.29c5.218 0 10.376-.117 15.453-.343c-4.985 6.774-10.018 12.97-15.028 18.486Zm52.198-57.817c3.422 7.8 6.306 15.345 8.596 22.52c-7.422 1.694-15.436 3.058-23.88 4.071a382.417 382.417 0 0 0 7.859-13.026a347.403 347.403 0 0 0 7.425-13.565Zm-16.898 8.101a358.557 358.557 0 0 1-12.281 19.815a329.4 329.4 0 0 1-23.444.823c-7.967 0-15.716-.248-23.178-.732a310.202 310.202 0 0 1-12.513-19.846h.001a307.41 307.41 0 0 1-10.923-20.627a310.278 310.278 0 0 1 10.89-20.637l-.001.001a307.318 307.318 0 0 1 12.413-19.761c7.613-.576 15.42-.876 23.31-.876H128c7.926 0 15.743.303 23.354.883a329.357 329.357 0 0 1 12.335 19.695a358.489 358.489 0 0 1 11.036 20.54a329.472 329.472 0 0 1-11 20.722Zm22.56-122.124c8.572 4.944 11.906 24.881 6.52 51.026c-.344 1.668-.73 3.367-1.15 5.09c-10.622-2.452-22.155-4.275-34.23-5.408c-7.034-10.017-14.323-19.124-21.64-27.008a160.789 160.789 0 0 1 5.888-5.4c18.9-16.447 36.564-22.941 44.612-18.3ZM128 90.808c12.625 0 22.86 10.235 22.86 22.86s-10.235 22.86-22.86 22.86s-22.86-10.235-22.86-22.86s10.235-22.86 22.86-22.86Z"></path></svg>

================
File: src/components/BackgroundAnimation.jsx
================
"use client"

import { useEffect, useRef } from "react"

const BackgroundAnimation = () => {
  const canvasRef = useRef(null)

  useEffect(() => {
    const canvas = canvasRef.current
    const ctx = canvas.getContext("2d")
    let animationFrameId

    // canvas dimensions to fill the window
    const setCanvasDimensions = () => {
      canvas.width = window.innerWidth
      canvas.height = window.innerHeight
    }

    // set initial canvas dimensions
    setCanvasDimensions()
    // initialize particles
    window.addEventListener("resize", setCanvasDimensions)

    const particlesArray = []
    const numberOfParticles = 100

    // Particle class
    // Each particle has a position, size, speed, and color
    // The update method updates the position of the particle
    // The draw method draws the particle on the canvas
    // The connect method connects particles with lines if they are close enough
    // The init method initializes the particles
    // The animate method clears the canvas and updates and draws each particle
    // It also connects the particles with lines
    // The animation loop is created using requestAnimationFrame
    // The animation loop is cancelled when the component unmounts
    // The particles are drawn with a gradient color
    // The particles move around the canvas and connect with each other
    // The particles are drawn with a gradient color
    class Particle {
      constructor() {
        this.x = Math.random() * canvas.width
        this.y = Math.random() * canvas.height
        this.size = Math.random() * 5 + 1
        this.speedX = Math.random() * 1 - 0.5
        this.speedY = Math.random() * 1 - 0.5
        this.color = `rgba(65, 105, 225, ${Math.random() * 0.3})`
      }

      update() {
        this.x += this.speedX
        this.y += this.speedY

        if (this.x > canvas.width) this.x = 0
        if (this.x < 0) this.x = canvas.width
        if (this.y > canvas.height) this.y = 0
        if (this.y < 0) this.y = canvas.height
      }

      draw() {
        ctx.fillStyle = this.color
        ctx.beginPath()
        ctx.arc(this.x, this.y, this.size, 0, Math.PI * 2)
        ctx.fill()
      }
    }

    const init = () => {
      for (let i = 0; i < numberOfParticles; i++) {
        particlesArray.push(new Particle())
      }
    }

    // Connect particles with lines if they are close enough
    // The connect method connects particles with lines if they are close enough
    // The distance between the particles is calculated using the Pythagorean theorem
    const connect = () => {
      for (let a = 0; a < particlesArray.length; a++) {
        for (let b = a; b < particlesArray.length; b++) {
          const dx = particlesArray[a].x - particlesArray[b].x
          const dy = particlesArray[a].y - particlesArray[b].y
          const distance = Math.sqrt(dx * dx + dy * dy)

          if (distance < 100) {
            ctx.strokeStyle = `rgba(65, 105, 225, ${0.15 - distance / 1000})`
            ctx.lineWidth = 1
            ctx.beginPath()
            ctx.moveTo(particlesArray[a].x, particlesArray[a].y)
            ctx.lineTo(particlesArray[b].x, particlesArray[b].y)
            ctx.stroke()
          }
        }
      }
    }

    init()

    const animate = () => {
      ctx.clearRect(0, 0, canvas.width, canvas.height)

      particlesArray.forEach((particle) => {
        particle.update()
        particle.draw()
      })

      connect()

      animationFrameId = requestAnimationFrame(animate)
    }

    animate()

    return () => {
      window.removeEventListener("resize", setCanvasDimensions)
      cancelAnimationFrame(animationFrameId)
    }
  }, [])

  // Style for the canvas to cover the entire screen  
  // and have a fixed position behind other elements
  // The background is a gradient

  const canvasStyle = {
    position: 'fixed',
    top: 0,
    left: 0,
    width: '100%',
    height: '100%',
    zIndex: -10,
    background: 'linear-gradient(to bottom, #eff6ff, #f5f5f5)', 
  }

  return <canvas ref={canvasRef} style={canvasStyle} />
}

export default BackgroundAnimation

================
File: src/components/CameraSection.jsx
================
"use client";

import { useRef, useState, useEffect } from "react";
import { Camera, X, Scan } from "lucide-react";

const CameraSection = ({ onDetectEmotion }) => {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const streamRef = useRef(null);
  const [isCameraOpen, setIsCameraOpen] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);

  // Open camera when requested
  const openCamera = async () => {
    try {
      console.log("Requesting camera...");
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "user",
          width: { ideal: 640 },
          height: { ideal: 480 },
        },
        audio: false,
      });

      console.log("Camera access granted, setting up video element");
      streamRef.current = stream;

      if (videoRef.current) {
        videoRef.current.srcObject = stream;

        // Wait for video to be loaded and then play it
        videoRef.current.addEventListener("loadedmetadata", () => {
          console.log("Video metadata loaded");
          videoRef.current
            .play()
            .then(() => {
              console.log("Video playback started");
              setIsCameraOpen(true);
            })
            .catch((error) => {
              console.error("Error playing video:", error);
            });
        });
      } else {
        console.error("Video element not found");
      }
    } catch (err) {
      console.error("Error accessing camera:", err);
      alert("Could not access camera. Please check your permissions.");
    }
  };

  // Close camera
  const closeCamera = () => {
    console.log("Closing camera");
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => {
        console.log("Stopping track:", track.kind);
        track.stop();
      });
      streamRef.current = null;

      if (videoRef.current) {
        videoRef.current.srcObject = null;
      }

      setIsCameraOpen(false);
    }
  };

  // Capture current frame and convert to base64
  const captureFrame = () => {
    if (!videoRef.current) return null;

    const canvas = canvasRef.current;
    const video = videoRef.current;
    const context = canvas.getContext("2d");

    // Set canvas dimensions to match video dimensions
    canvas.width = video.videoWidth || 640;
    canvas.height = video.videoHeight || 480;

    // Draw the current video frame to the canvas
    context.drawImage(video, 0, 0, canvas.width, canvas.height);

    // Convert canvas to base64 image
    return canvas.toDataURL("image/jpeg", 0.9);
  };

  // Handle emotion detection
  const handleDetect = async () => {
    try {
      setIsProcessing(true);
      const imageBase64 = captureFrame();

      if (!imageBase64) {
        throw new Error("Failed to capture image");
      }

      await onDetectEmotion(imageBase64);
    } catch (error) {
      console.error("Error during emotion detection:", error);
      alert("Error detecting emotion. Please try again.");
    } finally {
      setIsProcessing(false);
    }
  };

  // Clean up camera resources when component unmounts
  useEffect(() => {
    console.log("Setting up cleanup effect");
    return () => {
      console.log("Component unmounting, cleaning up camera");
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
        streamRef.current = null;
      }
    };
  }, []);

  // Debug for camera state
  useEffect(() => {
    console.log("Camera state changed:", isCameraOpen);
  }, [isCameraOpen]);

  const styles = {
    section: {
      marginBottom: "2.5rem",
      display: "flex",
      flexDirection: "column",
      alignItems: "center",
    },
    videoContainer: {
      position: "relative",
      width: "100%",
      maxWidth: "42rem",
      aspectRatio: "4/3",
      backgroundColor: "#f5f5f5",
      borderRadius: "0.5rem",
      overflow: "hidden",
      marginBottom: "1rem",
      display: "flex",
      justifyContent: "center",
      alignItems: "center",
    },
    video: {
      width: "100%",
      height: "100%",
      objectFit: "cover",
      display: isCameraOpen ? "block" : "none", // Explicitly show/hide based on state
    },
    canvas: {
      display: "none",
    },
    closeButton: {
      position: "absolute",
      top: "1rem",
      right: "1rem",
      backgroundColor: "rgba(38,38,38,0.7)",
      color: "#fff",
      padding: "0.5rem",
      borderRadius: "9999px",
      border: "none",
      cursor: "pointer",
      zIndex: 10,
    },
    placeholder: {
      color: "#737373",
      flexDirection: "column",
      alignItems: "center",
      display: isCameraOpen ? "none" : "flex", // Show only when camera is closed
    },
    buttonRow: {
      display: "flex",
      gap: "1rem",
    },
    openButton: {
      display: "flex",
      alignItems: "center",
      gap: "0.5rem",
      backgroundColor: "#262626",
      color: "#fff",
      padding: "0.75rem 1.5rem",
      borderRadius: "0.5rem",
      border: "none",
      cursor: "pointer",
    },
    detectButton: {
      display: "flex",
      alignItems: "center",
      gap: "0.5rem",
      backgroundColor: isProcessing ? "#737373" : "#404040",
      color: "#fff",
      padding: "0.75rem 1.5rem",
      borderRadius: "0.5rem",
      border: "none",
      cursor: isProcessing ? "not-allowed" : "pointer",
      opacity: isProcessing ? 0.7 : 1,
    },
  };

  return (
    <section style={styles.section}>
      <div style={styles.videoContainer}>
        {/* Always render the video element but control visibility with CSS */}
        <video ref={videoRef} autoPlay playsInline style={styles.video} muted />

        {/* Placeholder shown when camera is not open */}
        <div style={styles.placeholder}>
          <Camera
            style={{ height: "3rem", width: "3rem", marginBottom: "0.5rem" }}
          />
          <p>Camera feed will appear here</p>
        </div>

        {/* Show close button when camera is open */}
        {isCameraOpen && (
          <button
            onClick={closeCamera}
            style={styles.closeButton}
            aria-label="Close camera"
          >
            <X style={{ height: "1.25rem", width: "1.25rem" }} />
          </button>
        )}
      </div>

      {/* Hidden canvas for processing video frames */}
      <canvas ref={canvasRef} style={styles.canvas}></canvas>

      {/* Button to open camera or detect emotion */}
      <div style={styles.buttonRow}>
        {!isCameraOpen ? (
          <button onClick={openCamera} style={styles.openButton}>
            <Camera style={{ height: "1.25rem", width: "1.25rem" }} />
            Open Camera
          </button>
        ) : (
          <button
            onClick={handleDetect}
            style={styles.detectButton}
            disabled={isProcessing}
          >
            <Scan style={{ height: "1.25rem", width: "1.25rem" }} />
            {isProcessing ? "Processing..." : "Detect Emotion"}
          </button>
        )}
      </div>
    </section>
  );
};

export default CameraSection;

================
File: src/components/Footer.jsx
================
import { Github } from "lucide-react"
import { useState } from "react"

const Footer = () => {
  const [isHovered, setIsHovered] = useState(false)

  const styles = {
    footer: {
      padding: '1.5rem 0',
      textAlign: 'center',
      color: '#737373',
      fontSize: '0.875rem',
    },
    container: {
      display: 'flex',
      flexDirection: 'column',
      alignItems: 'center',
      justifyContent: 'center',
      marginBottom: '.5rem',
    },
    githubLink: {
      display: 'inline-flex',
      marginBottom: '0.75rem',
      transition: 'transform 0.2s ease, color 0.2s ease',
      transform: isHovered ? 'scale(1.1)' : 'scale(1)',
      color: isHovered ? '#404040' : '#737373',
      textDecoration: 'none',
    },
    disclaimer: {
      marginTop: '0.25rem',
    },
  }

  // On hover, scale the GitHub logo and change the link color to black
  

  return (
    <footer style={styles.footer}>
      <div style={styles.container}>
        <a
          href="https://github.com/Nguyen379/CS480---Final-Project"
          target="_blank"
          rel="noopener noreferrer"
          style={styles.githubLink}
          onMouseEnter={() => setIsHovered(true)}
          onMouseLeave={() => setIsHovered(false)}
          aria-label="GitHub Repository"
        >
          <Github style={{ height: '3rem', width: '3rem' }} />
        </a>
        <p>Feelosophy</p>
      </div>
      <p style={styles.disclaimer}>Final Project by Ritika, Anna, Nguyen, and Harold.</p>
    </footer>
  )
}

export default Footer

================
File: src/components/Header.jsx
================
const Header = () => {
  const styles = {
    header: {
      padding: '1.5rem 1rem',
      display: 'flex',
      alignItems: 'center',
      justifyContent: 'center',
    },
    container: {
      display: 'flex',
      alignItems: 'center',
      gap: '0.75rem',
    },
    title: {
      fontSize: '1.875rem', // text-3xl
      fontWeight: 'bold',
      color: '#262626', // neutral-800
      margin: 0,
    },
  }

  return (
    <header style={styles.header}>
      <div style={styles.container}>
        <h1 style={styles.title}>FEELOSOPHY</h1>
      </div>
    </header>
  )
}

export default Header

================
File: src/components/InfoSection.jsx
================
import { Info, Brain, Shield, Zap } from "lucide-react"

const InfoSection = () => {
  const styles = {
    section: {
      marginBottom: '4rem',
      width: '100%',
      maxWidth: '48rem',
      marginInline: 'auto',
    },
    heading: {
      fontSize: '1.5rem',
      fontWeight: 600,
      marginBottom: '1.5rem',
      color: '#262626',
      display: 'flex',
      alignItems: 'center',
      gap: '0.5rem',
    },
    card: {
      backgroundColor: '#fff',
      borderRadius: '0.5rem',
      boxShadow: '0 4px 6px rgba(0, 0, 0, 0.1)',
      padding: '1.5rem',
    },
    paragraph: {
      color: '#404040',
      marginBottom: '1.5rem',
      lineHeight: '1.75',
    },
    grid: {
      display: 'grid',
      gap: '1.5rem',
      marginTop: '2rem',
      gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))',
    },
    feature: {
      display: 'flex',
      flexDirection: 'column',
      alignItems: 'center',
      textAlign: 'center',
    },
    iconCircle: {
      backgroundColor: '#f5f5f5',
      padding: '1rem',
      borderRadius: '9999px',
      marginBottom: '1rem',
    },
    featureTitle: {
      fontWeight: 500,
      color: '#262626',
      marginBottom: '0.5rem',
    },
    featureText: {
      fontSize: '0.875rem',
      color: '#525252',
    },
    sectionDivider: {
      marginTop: '2rem',
      paddingTop: '1.5rem',
      borderTop: '1px solid #e5e5e5',
    },
    appTitle: {
      fontWeight: 500,
      color: '#262626',
      marginBottom: '0.75rem',
    },
    ul: {
      paddingLeft: '1.25rem',
      color: '#404040',
    },
    li: {
      marginBottom: '0.5rem',
    },
  }

  return (
    <section style={styles.section}>
      <h2 style={styles.heading}>
        <Info style={{ height: '1.5rem', width: '1.5rem' }} />
        About Feelosophy
      </h2>

      <div style={styles.card}>
        <p style={styles.paragraph}>
          Feelosophy uses computer vision and machine learning algorithms to detect and analyze human
          emotions in real-time. Our project can identify primary emotions like happiness, sadness, anger,
          surprise, fear, etc. 
        </p>

        <div style={styles.grid}>
          <div style={styles.feature}>
            <div style={styles.iconCircle}>
              <Brain style={{ height: '1.5rem', width: '1.5rem', color: '#404040' }} />
            </div>
            <h3 style={styles.featureTitle}> Artificial Intelligence and Machine Learning</h3>
            <p style={styles.featureText}>
              Powered by neural networks trained on more than 28000 facial expressions from FER 2013 dataset and tested on around 7000 faces.
            </p>
          </div>

          <div style={styles.feature}>
            <div style={styles.iconCircle}>
              <Shield style={{ height: '1.5rem', width: '1.5rem', color: '#404040' }} />
            </div>
            <h3 style={styles.featureTitle}>Privacy-Focused</h3>
            <p style={styles.featureText}>
              All processing happens locally in the browser and no images are stored or sent to other databases.
            </p>
          </div>

          <div style={styles.feature}>
            <div style={styles.iconCircle}>
              <Zap style={{ height: '1.5rem', width: '1.5rem', color: '#404040' }} />
            </div>
            <h3 style={styles.featureTitle}>Real-Time Analysis</h3>
            <p style={styles.featureText}>
              Get immediate emotion detection results.
            </p>
          </div>
        </div>

        <div style={styles.sectionDivider}>
          <h3 style={styles.appTitle}>Potential Applications</h3>
          <ul style={styles.ul}>
            <li style={styles.li}>User experience research and testing</li>
            <li style={styles.li}>Mental health monitoring and support</li>
            <li style={styles.li}>Educational tools for emotional intelligence</li>
            <li style={styles.li}>Customer satisfaction analysis</li>
            <li style={styles.li}>Interactive entertainment and gaming</li>
          </ul>
        </div>
      </div>
    </section>
  )
}

export default InfoSection

================
File: src/components/ResultsPanel.jsx
================
"use client";

import { useState, useEffect } from "react";
import { BarChart, SmilePlus, Loader } from "lucide-react";

const ResultsPanel = ({ result, isLoading }) => {
  const [animate, setAnimate] = useState(false);

  useEffect(() => {
    if (result) {
      setAnimate(true);
      const timer = setTimeout(() => setAnimate(false), 1000);
      return () => clearTimeout(timer);
    }
  }, [result]);

  const styles = {
    section: {
      marginBottom: "3rem",
      width: "100%",
      maxWidth: "42rem",
      marginInline: "auto",
    },
    heading: {
      fontSize: "1.5rem",
      fontWeight: 600,
      marginBottom: "1rem",
      color: "#262626",
      display: "flex",
      alignItems: "center",
      gap: "0.5rem",
    },
    card: {
      backgroundColor: "#fff",
      borderRadius: "0.5rem",
      boxShadow: "0 4px 6px rgba(0,0,0,0.1)",
      padding: "1.5rem",
      transform: animate ? "scale(1.05)" : "scale(1)",
      transition: "transform 0.5s ease",
    },
    primaryBox: {
      marginBottom: "1.5rem",
      textAlign: "center",
    },
    primaryTitle: {
      fontSize: "1.25rem",
      fontWeight: 500,
      color: "#404040",
    },
    primaryEmotion: {
      fontSize: "1.875rem",
      fontWeight: 700,
      marginTop: "0.5rem",
      color: "#171717",
    },
    confidenceText: {
      marginTop: "0.25rem",
      color: "#737373",
    },
    subheading: {
      display: "flex",
      alignItems: "center",
      gap: "0.5rem",
      marginBottom: "0.75rem",
    },
    subheadingText: {
      fontWeight: 500,
      color: "#404040",
    },
    emotionBarWrapper: {
      display: "flex",
      justifyContent: "space-between",
      marginBottom: "0.25rem",
    },
    emotionLabel: {
      fontSize: "0.875rem",
      fontWeight: 500,
      color: "#404040",
    },
    confidenceLabel: {
      fontSize: "0.875rem",
      color: "#737373",
    },
    barBackground: {
      width: "100%",
      backgroundColor: "#e5e5e5",
      borderRadius: "9999px",
      height: "0.5rem",
    },
    barForeground: (width) => ({
      width: `${width}%`,
      backgroundColor: "#404040",
      height: "0.5rem",
      borderRadius: "9999px",
      transition: "width 1s ease-out",
    }),
    placeholder: {
      padding: "2rem 0",
      textAlign: "center",
      color: "#737373",
    },
    iconPlaceholder: {
      height: "3rem",
      width: "3rem",
      opacity: 0.5,
      margin: "0 auto 0.75rem auto",
    },
    loading: {
      display: "flex",
      flexDirection: "column",
      alignItems: "center",
      justifyContent: "center",
      padding: "3rem 0",
    },
    spinner: {
      animation: "spin 1s linear infinite",
      margin: "0 auto 1rem auto",
    },
    "@keyframes spin": {
      "0%": { transform: "rotate(0deg)" },
      "100%": { transform: "rotate(360deg)" },
    },
  };

  return (
    <section style={styles.section}>
      <h2 style={styles.heading}>
        <SmilePlus style={{ height: "1.5rem", width: "1.5rem" }} />
        How are you feeling today?
      </h2>

      <div style={styles.card}>
        {isLoading ? (
          <div style={styles.loading}>
            <Loader
              style={{
                height: "2rem",
                width: "2rem",
                color: "#404040",
                animation: "spin 1s linear infinite",
                marginBottom: "0.75rem",
              }}
            />
            <p>Analyzing your expression...</p>
          </div>
        ) : result ? (
          <div>
            <div style={styles.primaryBox}>
              <h3 style={styles.primaryTitle}>Primary Emotion Detected</h3>
              <p style={styles.primaryEmotion}>{result.primaryEmotion}</p>
              <p style={styles.confidenceText}>
                Confidence: {result.confidence.toFixed(1)}%
              </p>
            </div>

            <div>
              <div style={styles.subheading}>
                <BarChart
                  style={{
                    height: "1.25rem",
                    width: "1.25rem",
                    color: "#404040",
                  }}
                />
                <h4 style={styles.subheadingText}>All Detected Emotions</h4>
              </div>

              <div
                style={{
                  display: "flex",
                  flexDirection: "column",
                  gap: "0.75rem",
                }}
              >
                {result.allResults.map((item, index) => (
                  <div key={index}>
                    <div style={styles.emotionBarWrapper}>
                      <span style={styles.emotionLabel}>{item.emotion}</span>
                      <span style={styles.confidenceLabel}>
                        {typeof item.confidence === "number"
                          ? (item.confidence * 100).toFixed(1)
                          : parseFloat(item.confidence * 100).toFixed(1)}
                        %
                      </span>
                    </div>
                    <div style={styles.barBackground}>
                      <div
                        style={styles.barForeground(item.confidence * 100)}
                      ></div>
                    </div>
                  </div>
                ))}
              </div>
            </div>
          </div>
        ) : (
          <div style={styles.placeholder}>
            <SmilePlus style={styles.iconPlaceholder} />
            <p>Open the camera and click "Detect Emotion" to analyze.</p>
          </div>
        )}
      </div>
    </section>
  );
};

export default ResultsPanel;

================
File: src/services/api.js
================
// API service for facial emotion detection

// Base URL for the backend API
const API_BASE_URL = "http://localhost:3000";

/**
 * Detects emotion from a base64-encoded image
 * @param {string} imageBase64 - Base64 encoded image
 * @returns {Promise<Object>} - Emotion detection results
 */
export const detectEmotion = async (imageBase64) => {
	try {
		const response = await fetch(`${API_BASE_URL}/detect`, {
			method: "POST",
			headers: {
				"Content-Type": "application/json",
			},
			body: JSON.stringify({ image: imageBase64 }),
		});

		if (!response.ok) {
			const errorData = await response.json();
			throw new Error(errorData.error || "Failed to detect emotion");
		}

		return await response.json();
	} catch (error) {
		console.error("Error detecting emotion:", error);
		throw error;
	}
};

================
File: src/App.css
================
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: "Inter", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans",
    "Helvetica Neue", sans-serif;
  color: #333;
  background-color: #f5f5f5;
}

.app {
  position: relative;
  min-height: 100vh;
}

.content {
  max-width: 1200px;
  margin: 0 auto;
  padding: 0 1rem;
  position: relative;
  z-index: 1;
}

main {
  display: flex;
  flex-direction: column;
  align-items: center;
  padding: 2rem 0;
}

button {
  cursor: pointer;
  border: none;
  font-family: inherit;
}

button:focus {
  outline: 2px solid #666;
  outline-offset: 2px;
}

@media (max-width: 768px) {
  main {
    padding: 1rem 0;
  }
}

================
File: src/App.jsx
================
"use client";

import { useState } from "react";
import Header from "./components/Header";
import CameraSection from "./components/CameraSection";
import ResultsPanel from "./components/ResultsPanel";
import InfoSection from "./components/InfoSection";
import Footer from "./components/Footer";
import BackgroundAnimation from "./components/BackgroundAnimation";
import "./App.css";

// Define a mock detection function
// Note: We use the imageBase64 parameter to avoid the TypeScript warning
const mockDetectEmotion = async (imageBase64) => {
  console.log(
    "Using mock detection for image data length:",
    imageBase64.length
  );

  // Simulate API delay
  await new Promise((resolve) => setTimeout(resolve, 1000));

  // Create mock data
  const emotions = [
    "Happy",
    "Sad",
    "Angry",
    "Surprised",
    "Neutral",
    "Fearful",
    "Disgusted",
  ];
  const confidences = Array(7)
    .fill()
    .map(() => Math.random());

  // Normalize confidences so they sum to 1
  const sum = confidences.reduce((a, b) => a + b, 0);
  const normalizedConfidences = confidences.map((c) => c / sum);

  // Create results
  const results = emotions
    .map((emotion, index) => ({
      emotion,
      confidence: normalizedConfidences[index],
    }))
    .sort((a, b) => b.confidence - a.confidence);

  return {
    primaryEmotion: results[0].emotion,
    confidence: results[0].confidence * 100,
    allResults: results,
  };
};

// Set up initial detection function to mock
let detectEmotion = mockDetectEmotion;

// Try to import the real API function
import("./services/api")
  .then((api) => {
    detectEmotion = api.detectEmotion;
    console.log("Successfully imported API service");
  })
  .catch((err) => {
    console.error("Error importing API service, using mock data:", err);
    // Keep using the mock function
  });

function App() {
  const [detectionResult, setDetectionResult] = useState(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState(null);

  const handleDetectEmotion = async (imageBase64) => {
    try {
      setIsLoading(true);
      setError(null);

      // Call the API to detect emotion
      const result = await detectEmotion(imageBase64);
      setDetectionResult(result);
    } catch (err) {
      console.error("Error in emotion detection:", err);
      setError("Failed to detect emotion. Please try again.");
      setDetectionResult(null);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="app">
      <BackgroundAnimation />
      <div className="content">
        <Header />
        <main>
          {error && (
            <div
              style={{
                padding: "0.75rem",
                backgroundColor: "#fecaca",
                border: "1px solid #ef4444",
                borderRadius: "0.375rem",
                marginBottom: "1rem",
                color: "#b91c1c",
                width: "100%",
                maxWidth: "42rem",
                textAlign: "center",
              }}
            >
              {error}
            </div>
          )}

          <CameraSection onDetectEmotion={handleDetectEmotion} />

          <ResultsPanel result={detectionResult} isLoading={isLoading} />

          <InfoSection />
        </main>
        <Footer />
      </div>
    </div>
  );
}

export default App;

================
File: src/main.jsx
================
import React from "react"
import ReactDOM from "react-dom/client"
import App from "./App.jsx"
import "./App.css"

ReactDOM.createRoot(document.getElementById("root")).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
)

================
File: .gitattributes
================
# Auto detect text files and perform LF normalization
* text=auto

================
File: .gitignore
================
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

================
File: eslint.config.js
================
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'

export default [
  { ignores: ['dist'] },
  {
    files: ['**/*.{js,jsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    plugins: {
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...js.configs.recommended.rules,
      ...reactHooks.configs.recommended.rules,
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
]

================
File: index.html
================
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>FEELOSOPHY</title>
    <meta name="description" content="Detect and analyze emotions in real-time using advanced AI technology" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>

================
File: LICENSE
================
MIT License

Copyright (c) 2025 Le Anh Nguyen

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: package.json
================
{
  "name": "emotion-detection",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "lucide-react": "^0.503.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  },
  "devDependencies": {
    "@eslint/js": "^9.22.0",
    "@types/react": "^19.0.10",
    "@types/react-dom": "^19.0.4",
    "@vitejs/plugin-react": "^4.3.4",
    "autoprefixer": "^10.4.21",
    "eslint": "^9.22.0",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.19",
    "globals": "^16.0.0",
    "postcss": "^8.5.3",
    "tailwindcss": "^4.1.4",
    "vite": "^6.3.1"
  }
}

================
File: README.md
================
# CS480 - Final Project
 CS 480 Final Project

npm install
npm install lucide-react
npm run dev

================
File: vite.config.js
================
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})
